{
  "paragraphs": [
    {
      "text": "sc.version",
      "user": "sperambalam@qubole.com",
      "dateUpdated": "Aug 29, 2017 5:43:02 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1504028559514_-1720154873",
      "id": "20170829-174239_1686491722",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nres0: String \u003d 1.5.1\n"
      },
      "dateCreated": "Aug 29, 2017 5:42:39 PM",
      "dateStarted": "Aug 29, 2017 5:43:02 PM",
      "dateFinished": "Aug 29, 2017 5:44:32 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "sc.parallelize(1 to 10).collect",
      "user": "sperambalam@qubole.com",
      "dateUpdated": "Aug 29, 2017 5:45:27 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1504028582199_959282439",
      "id": "20170829-174302_737302525",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nres0: Array[Int] \u003d Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n"
      },
      "dateCreated": "Aug 29, 2017 5:43:02 PM",
      "dateStarted": "Aug 29, 2017 5:45:27 PM",
      "dateFinished": "Aug 29, 2017 5:46:21 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "sc.parallelize (2 to 20).collect",
      "user": "sperambalam@qubole.com",
      "dateUpdated": "Aug 29, 2017 5:45:31 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1504028633464_-1120407959",
      "id": "20170829-174353_624016960",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nres2: Array[Int] \u003d Array(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)\n"
      },
      "dateCreated": "Aug 29, 2017 5:43:53 PM",
      "dateStarted": "Aug 29, 2017 5:45:31 PM",
      "dateFinished": "Aug 29, 2017 5:46:23 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "sc.stop",
      "user": "sperambalam@qubole.com",
      "dateUpdated": "Aug 29, 2017 5:44:27 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1504028657927_1376040475",
      "id": "20170829-174417_121603878",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Aug 29, 2017 5:44:17 PM",
      "dateStarted": "Aug 29, 2017 5:44:39 PM",
      "dateFinished": "Aug 29, 2017 5:44:40 PM",
      "status": "ABORT",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\npip install plotly",
      "user": "sperambalam@qubole.com",
      "dateUpdated": "Aug 29, 2017 6:25:13 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/sh"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1504028667038_2079376788",
      "id": "20170829-174427_1083788323",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "Collecting plotly\n  Downloading plotly-2.0.15.tar.gz (1.0MB)\nCollecting decorator\u003e\u003d4.0.6 (from plotly)\n  Downloading decorator-4.1.2-py2.py3-none-any.whl\nCollecting nbformat\u003e\u003d4.2 (from plotly)\n  Downloading nbformat-4.4.0-py2.py3-none-any.whl (155kB)\nRequirement already satisfied: pytz in /usr/lib/python2.7/dist-packages (from plotly)\nRequirement already satisfied: requests in /usr/lib/python2.7/dist-packages (from plotly)\nRequirement already satisfied: six in /usr/lib/python2.7/dist-packages (from plotly)\nCollecting traitlets\u003e\u003d4.1 (from nbformat\u003e\u003d4.2-\u003eplotly)\n  Downloading traitlets-4.3.2-py2.py3-none-any.whl (74kB)\nCollecting jupyter-core (from nbformat\u003e\u003d4.2-\u003eplotly)\n  Downloading jupyter_core-4.3.0-py2.py3-none-any.whl (76kB)\nCollecting jsonschema!\u003d2.5.0,\u003e\u003d2.4 (from nbformat\u003e\u003d4.2-\u003eplotly)\n  Downloading jsonschema-2.6.0-py2.py3-none-any.whl\nCollecting ipython-genutils (from nbformat\u003e\u003d4.2-\u003eplotly)\n  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl\nRequirement already satisfied: urllib3\u003c1.22,\u003e\u003d1.21.1 in /usr/lib/python2.7/dist-packages (from requests-\u003eplotly)\nRequirement already satisfied: idna\u003c2.6,\u003e\u003d2.5 in /usr/lib/python2.7/dist-packages (from requests-\u003eplotly)\nRequirement already satisfied: certifi\u003e\u003d2017.4.17 in /usr/lib/python2.7/dist-packages (from requests-\u003eplotly)\nRequirement already satisfied: chardet\u003c3.1.0,\u003e\u003d3.0.2 in /usr/lib/python2.7/dist-packages (from requests-\u003eplotly)\nRequirement already satisfied: enum34; python_version \u003d\u003d \"2.7\" in /usr/lib/python2.7/dist-packages (from traitlets\u003e\u003d4.1-\u003enbformat\u003e\u003d4.2-\u003eplotly)\nCollecting functools32; python_version \u003d\u003d \"2.7\" (from jsonschema!\u003d2.5.0,\u003e\u003d2.4-\u003enbformat\u003e\u003d4.2-\u003eplotly)\n  Downloading functools32-3.2.3-2.zip\nBuilding wheels for collected packages: plotly, functools32\n  Running setup.py bdist_wheel for plotly: started\n  Running setup.py bdist_wheel for plotly: finished with status \u0027done\u0027\n  Stored in directory: /root/.cache/pip/wheels/c9/c4/00/a80b040dd8c9301d29f7153881c96edf1cd8561977ec440941\n  Running setup.py bdist_wheel for functools32: started\n  Running setup.py bdist_wheel for functools32: finished with status \u0027done\u0027\n  Stored in directory: /root/.cache/pip/wheels/3c/d0/09/cd78d0ff4d6cfecfbd730782a7815a4571cd2cd4d2ed6e69d9\nSuccessfully built plotly functools32\nInstalling collected packages: decorator, ipython-genutils, traitlets, jupyter-core, functools32, jsonschema, nbformat, plotly\n  Found existing installation: decorator 3.3.2\n    Uninstalling decorator-3.3.2:\n      Successfully uninstalled decorator-3.3.2\nSuccessfully installed decorator-4.1.2 functools32-3.2.3.post2 ipython-genutils-0.2.0 jsonschema-2.6.0 jupyter-core-4.3.0 nbformat-4.4.0 plotly-2.0.15 traitlets-4.3.2\n"
      },
      "dateCreated": "Aug 29, 2017 5:44:27 PM",
      "dateStarted": "Aug 29, 2017 6:25:13 PM",
      "dateFinished": "Aug 29, 2017 6:25:40 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\ncreate table emploee (name varchar 255, id int);",
      "user": "sperambalam@qubole.com",
      "dateUpdated": "Aug 29, 2017 6:26:47 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1504031113150_-517599498",
      "id": "20170829-182513_1143358513",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "line 1:35 missing ( at \u0027255\u0027 near \u0027\u003cEOF\u003e\u0027\nline 1:38 missing ) at \u0027,\u0027 near \u0027\u003cEOF\u003e\u0027\nline 1:47 extraneous input \u0027;\u0027 expecting EOF near \u0027\u003cEOF\u003e\u0027;\nset zeppelin.spark.sql.stacktrace \u003d true to see full stacktrace"
      },
      "dateCreated": "Aug 29, 2017 6:25:13 PM",
      "dateStarted": "Aug 29, 2017 6:26:47 PM",
      "dateFinished": "Aug 29, 2017 6:27:41 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val bankText \u003d sc.textFile(\"/Downloads/bank/bank-full.csv\")\n\ncase class Bank(age:Integer, job:String, marital : String, education : String, balance : Integer)\n\n// split each line, filter out header (starts with \"age\"), and map it into Bank case class  \nval bank \u003d bankText.map(s\u003d\u003es.split(\";\")).filter(s\u003d\u003es(0)!\u003d\"\\\"age\\\"\").map(\n    s\u003d\u003eBank(s(0).toInt, \n            s(1).replaceAll(\"\\\"\", \"\"),\n            s(2).replaceAll(\"\\\"\", \"\"),\n            s(3).replaceAll(\"\\\"\", \"\"),\n            s(5).replaceAll(\"\\\"\", \"\").toInt\n        )\n)\n\n// convert to DataFrame and create temporal table\nbank.toDF().registerTempTable(\"bank\")",
      "user": "sperambalam@qubole.com",
      "dateUpdated": "Aug 29, 2017 6:31:04 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1504031207903_-1004737578",
      "id": "20170829-182647_914422611",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nbankText: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[1] at textFile at \u003cconsole\u003e:23\n\ndefined class Bank\n\nbank: org.apache.spark.rdd.RDD[Bank] \u003d MapPartitionsRDD[4] at map at \u003cconsole\u003e:27\n"
      },
      "dateCreated": "Aug 29, 2017 6:26:47 PM",
      "dateStarted": "Aug 29, 2017 6:31:04 PM",
      "dateFinished": "Aug 29, 2017 6:31:12 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql select age, count(1) from bank where age \u003c 30 group by age order by age",
      "user": "sperambalam@qubole.com",
      "dateUpdated": "Aug 29, 2017 6:31:37 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1504031464891_1056517689",
      "id": "20170829-183104_10265463",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "java.io.FileNotFoundException: File does not exist: hdfs://ec2-54-235-60-72.compute-1.amazonaws.com:9000/Downloads/bank/bank-full.csv\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:1122)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:1114)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1114)\n\tat org.apache.hadoop.fs.FileSystem.resolvePath(FileSystem.java:756)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$16.\u003cinit\u003e(DistributedFileSystem.java:779)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.listLocatedStatus(DistributedFileSystem.java:770)\n\tat org.apache.hadoop.mapred.InputPathProcessor.perPathComputation(InputPathProcessor.java:251)\n\tat org.apache.hadoop.mapred.InputPathProcessor.access$000(InputPathProcessor.java:28)\n\tat org.apache.hadoop.mapred.InputPathProcessor$2.run(InputPathProcessor.java:354)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:573)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1932)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2052)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1003)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:985)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1.apply(RDD.scala:1366)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.takeOrdered(RDD.scala:1353)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProject.collectData(basicOperators.scala:257)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProject.executeCollect(basicOperators.scala:263)\n\tat org.apache.spark.sql.DataFrame$$anonfun$collect$1.apply(DataFrame.scala:1385)\n\tat org.apache.spark.sql.DataFrame$$anonfun$collect$1.apply(DataFrame.scala:1385)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.DataFrame.withNewExecutionId(DataFrame.scala:1903)\n\tat org.apache.spark.sql.DataFrame.collect(DataFrame.scala:1384)\n\tat org.apache.spark.sql.DataFrame.head(DataFrame.scala:1314)\n\tat org.apache.spark.sql.DataFrame.take(DataFrame.scala:1377)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.zeppelin.spark.ZeppelinContext.showDF(ZeppelinContext.java:226)\n\tat org.apache.zeppelin.spark.SparkSqlInterpreter.interpret(SparkSqlInterpreter.java:151)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:103)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:413)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:185)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n"
      },
      "dateCreated": "Aug 29, 2017 6:31:04 PM",
      "dateStarted": "Aug 29, 2017 6:31:37 PM",
      "dateFinished": "Aug 29, 2017 6:31:39 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val file \u003d sc.textFile(\"s3://paid-qubole/default-datasets/gutenberg/pg20417.txt\")\nval counts \u003d file.flatMap(line \u003d\u003e line.split(\" \")).\nmap(word \u003d\u003e (word, 1)).\nreduceByKey(_+_).\nmap(item \u003d\u003e item.swap).  // interchanges position of entries in each tuple\nsortByKey(false).\nmap(item \u003d\u003e item.swap).  // interchanges position of entries in each tuple\ntake(10)\n\ncounts.foreach(println)",
      "user": "sperambalam@qubole.com",
      "dateUpdated": "Sep 7, 2017 8:51:40 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1504031497495_188771002",
      "id": "20170829-183137_865171983",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nfile: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[1] at textFile at \u003cconsole\u003e:23\n\ncounts: Array[(String, Int)] \u003d Array((\"\",14637), (the,7906), (of,5425), (and,2759), (a,2422), (to,2168), (is,2068), (in,2048), (that,1273), (are,921))\n(,14637)\n(the,7906)\n(of,5425)\n(and,2759)\n(a,2422)\n(to,2168)\n(is,2068)\n(in,2048)\n(that,1273)\n(are,921)\n"
      },
      "dateCreated": "Aug 29, 2017 6:31:37 PM",
      "dateStarted": "Sep 7, 2017 8:51:40 PM",
      "dateFinished": "Sep 7, 2017 8:53:09 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1504817500035_-1120487595",
      "id": "20170907-205140_289675648",
      "dateCreated": "Sep 7, 2017 8:51:40 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "ShivaTest",
  "id": "5XYW8JYGVB1504028553",
  "angularObjects": {
    "2CQJTH6M2184741503698389066:shared_process": [],
    "2CR22ABK2184741503698389050:shared_process": [],
    "2CTU2EXMX184741503698389058:shared_process": [],
    "2CSN8EQQ6184741503698389020:shared_process": []
  },
  "config": {
    "isDashboard": false
  },
  "info": {},
  "source": "FCN"
}